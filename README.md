# DataWarehouse



## ETL

### 概览

​	项目数据来源：使用[https://nijianmo.github.io/amazon/index.html](https://nijianmo.github.io/amazon/index.html)的 “Small” subsets for experimentation 中的 Movies and TV 5-core 一共3,410,019条用户商品评论信息，利用数据中的“asin”字段对亚马逊页面进行信息爬取。

​	在对其中的“asin”字段进行去重处理后，总共得到了60172条不重复的asin数据，保存为csv文件；通过亚马逊商品页面中的imdb标签对商品进行区分，判断其是否是电影；采用IP代理池和python线程池来提高爬取的效率；数据存储采用三种不同数据库：MySQL、Neo4j、Hive，综合对比不同数据库的查询性能差异

>### ETL使用教程
>
>⭕️⭕️⭕️⭕️⭕️
>
>
>
>



### Extract

+ #### 爬虫

  + 首先对源数据进行处理之后，得到其asin字段的csv文件，利用其asin字段构造一系列Amazon商品页面的url 

    ```python
    asin = "157252765X"
    url = 'https://www.amazon.com/dp/ + asin
    ```

  + 使用request库发送请求

    ```python
    strhtml = requests.get(url, headers=web_header, cookies=cookies, proxies={"http": "http://{}".format(proxy)})
    ```
    需要注意的是，爬取亚马逊的页面必须要包括基本的请求头以及cookies等基本内容，否则无法大量爬取
    
  + 使用lxml和beautifulsoup库解析网页，通过selector获取相关字段
  
    ```python
    soup = BeautifulSoup(strhtml.text, 'lxml')
    movie_title = str(soup.select('title')[0].getText())
    ```
    
  + 使用python线程池
    
    ```python
    with ThreadPoolExecutor(8) as t:
        for item in reader:
            if reader.line_num < 2:
                continue
            if reader.line_num > 15000:
                break
            url = 'https://www.amazon.com/dp/' + item[0]
            future = t.submit(download_one_page, url, reader.line_num)
            future.add_done_callback(executor_callback)
            t.shutdown()
    ```
    
    相比python多线程，线程池可以提供更加方便的使用策略，线程池中的线程是重复使用的，在其分配的任务被完成完成后，它会继续被分配任务；而多线程需要重复启动线程，这样会浪费系统资源
    
    需要注意的是，在线程中的错误是不会被影响到主线程，也就是说，子线程出现错误后会被分配下一个任务，而主线程不会终止，自然也没有错误输出
    
  +  使用IP代理池
    
    在不使用IP代理池时，爬取过程只能维持短时间（20～30min）的高成功率（85%以上），之后单次爬取的成功率会降低到（10%）以下，但当切换IP之后（使用手机热点等），其爬取成功率会恢复，但在上述时间之后，爬取成功率仍然会大幅降低。同一个IP需要暂停一段时间才能重新恢复到初始状态，但具体时间无法得知，（上限可知：超过12h）
    
    所以需要进行IP代理来提高长时间段内的爬取成功率：
    
    [proxy_pool](https://github.com/jhao104/proxy_pool)
    
    [ProxyPool](https://github.com/Python3WebSpider/ProxyPool)
    
    使用了以上两个代理池进行了可用代理IP的获取，具体使用过程请点击链接查看
    
    但上述IP池的数量并不是非常充足，因此采用了“先使用一个ip，当其爬取成功率降低到一定程度时，换用另一个ip“的策略
    
    
  
+ #### 数据暂存策略

  由于需要爬取的页面众多，不能一次性爬取完毕，所以在asin的csv文件中增加一列，用于记录已经爬取过的，或是已经确认不是movie的asin，这样可以多次关停程序，间断的爬取数据

### Transform

+ #### 电影系列判定

  采用Levenshtein距离算法，计算两个电影名称的相似度，同时根据实际情况设置不同情况的权重，比如减少长度相差过大的电影名称的相似度，降低某些无意义的单词（“The”， “At”）的权重，最后选取某一个相似度的界限，当相似度超过该值时，视两部电影为一个系列

+ #### 评论情感分析

  ⭕️⭕️⭕️⭕️⭕️⭕️⭕️

+ #### 其他

  ⭕️⭕️⭕️⭕️⭕️

### Load

+ #### MySQL

  存储数据库安装在Centos8.2的阿里云服务器上，因为存储时需要计算电影系列，时间复杂度是$O(n^2)$，因此存储脚本选择在服务器上挂起执行，节约本机资源

+ #### Neo4j

  ⭕️⭕️⭕️⭕️⭕️

+ #### Hive

  ⭕️⭕️⭕️⭕️⭕️

  

## 数据存储设计说明

### 整体存储模式

在关系型数据库的存储中，所有的所有的电影信息均被储存，并且对所有的查询接口进行了实现，但是对于关系型数据库，查询表于表之间的关系相对较慢，但是对于单个表上的字段的筛选较快。因此，在查询关系类的信息时，采用了图数据库的查询⭕️⭕️⭕️*（随便加点什么）*

### 关系型存储

关系型存储采用了MySQL，MySQL是现在最为常用几种关系型数据库之一，它对比其他的几种大型商业数据库来说，如Oracle， DB2和Sybase，非常的简单易用，同时MySQL的性能也非常稳定，很少出现宕机，同时也易于维护，安装。关系型数据库也是我们最常接触的几种数据库之一，对于相关的问题也网络上也有相当多的解答

+ #### ER图设计

  ![数据仓库ER图](README.assets/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93ER%E5%9B%BE.png)

  存储的设计中，我们采用了具有部分冗余的星型模型作为关系型数据库MySQL的存储模型，这种模型是不符合规范的数据库设计，但是这种设计能够在频繁查询中提供较好的性能，相比之下，雪花模型在存储时，没有存储冗余的数据，在查询相关的数据时，往往需要在多个表的信息中进行搜索，因此更新查询星型模型会快于雪花模型。

+ #### 数据库er图

  ![mysql](README.assets/mysql.png)

  在数据库表中，分为一个事实表`fact_movie`和多个维度表`div_review`、`div_movie_series`、`div_style`、`div_actor`、`div_director`

  在各个表中存储了基础的冗余信息，便于查询操作，比如在`fact_movie`中存储了其电影的演员和导演信息、在导演和演员的表中存储了其演过的电影的信息，在时间表中存储了季度以及星期几的信息，在风格表和电影系列表中存储了电影数量的信息

+ #### 存储优化策略

  + ##### 字段类型选择

    在存储数据库的各信息时，尽可能的减少字段的浪费，对于各数据表的主键，均采用`int`类型，对于其余类型的主键，尽可能的设置少的字段来，比如在时间表中，除了主键外，均采用`tinyint`作为字段类型

  + ##### 字段冗余存储

    在各个表中存储了基础的冗余信息，便于查询操作，比如在`fact_movie`中存储了其电影的演员和导演信息、在导演和演员的表中存储了其演过的电影的信息，在时间表中存储了季度以及星期几的信息，在风格表和电影系列表中存储了电影数量的信息

  + ##### 索引

    对于各数据表，均设置了索引，来提高查询性能

    设置BTREE索引：

    ![截屏2021-12-20 下午10.03.30](README.assets/%E6%88%AA%E5%B1%8F2021-12-20%20%E4%B8%8B%E5%8D%8810.03.30.png)

    设置HASH索引：

    ![截屏2021-12-20 下午10.04.20](README.assets/%E6%88%AA%E5%B1%8F2021-12-20%20%E4%B8%8B%E5%8D%8810.04.20.png)

    未设置索引：

    ![截屏2021-12-20 下午10.03.30](README.assets/%E6%88%AA%E5%B1%8F2021-12-20%20%E4%B8%8B%E5%8D%8810.03.30.png)

### 分布式存储



### 图数据存储





## 项目报告



### 数据查询程序



#### 前端程序

前端采用了常用的Vue + Element UI的方法，调用后端接口进行数据获取和展示，进行查询的性能对比，使用e-chart图形化展示查询结果

[前端仓库地址](https://github.com/zb2313/DW_frontend)

[前端项目地址](http://139.196.202.57:8090/)



#### 后端程序

后端整体使用Spring Boot， 使用hibernate作为数据持久化框架，数据查询操作使用Spring Data JPA

[后端仓库地址](https://github.com/Wizard23333/DataWarehouseBackend)

##### 实现接口

+ 11个时间查询接口，包括各种组合类型的接口
+ 4个电影类接口，包括模糊查询和精确查询
+ 8个导演演员接口，查询基本信息和合作信息
+ 8个合作查询接口，查询经常合作的人员信息
+ 5个组合查询接口，通过两种参数进行查询

##### 查询示例

+ 类别统计

![截屏2021-12-21 上午10.18.50](README.assets/%E6%88%AA%E5%B1%8F2021-12-21%20%E4%B8%8A%E5%8D%8810.18.50.png)

+ 分数统计

![截屏2021-12-21 上午10.19.30](README.assets/%E6%88%AA%E5%B1%8F2021-12-21%20%E4%B8%8A%E5%8D%8810.19.30.png)

+ 参演电影随时间变化

![截屏2021-12-21 上午10.24.14](README.assets/%E6%88%AA%E5%B1%8F2021-12-21%20%E4%B8%8A%E5%8D%8810.24.14.png)

+ 参演电影类别统计

![截屏2021-12-21 上午10.25.55](README.assets/%E6%88%AA%E5%B1%8F2021-12-21%20%E4%B8%8A%E5%8D%8810.25.55.png)

+ 类别年份统计

![截屏2021-12-21 上午10.27.52](README.assets/%E6%88%AA%E5%B1%8F2021-12-21%20%E4%B8%8A%E5%8D%8810.27.52.png)

+ 类别分数统计

![截屏2021-12-21 上午10.31.36](README.assets/%E6%88%AA%E5%B1%8F2021-12-21%20%E4%B8%8A%E5%8D%8810.31.36.png)



### 存储优化分析

+ 对于一般的查询，比如查询某年某月有哪些电影，某个季度有哪些电影，某个类别有哪些电影，采用MySQL数据库比较迅速，如果在图数据库上执行相关的查询，速度较慢，因为不能直接对节点进行查询，首先需要查询关系，才能再查询节点的数据
+ 对于有多种关联的数据查询，比如查询经常合作的导演的榜单，经常合作的演员的榜单，需要使用图数据库Neo4j进行查询，使用MySQL进行查询的时候，需要多次查询多张数据表，再进行统计排序操作，因此时间复杂度较高；而对于图数据库，则只需要查询关系即可，因此查询速度较快
+ 在查询的时候，如果有设置有数据的冗余，则应选择冗余数据进行查询，这样相比一般的查询，不需要进行多张表的查询；同时在查询的时候，应该注意join的使用，如果两张表的数据量都非常大，join操作可能导致服务器的内存不够

+ ⭕️⭕️⭕️⭕️⭕️

### 数据质量分析

+ 在数据extract过程中，爬取网页时亚马逊页面会有两种显示页面，在爬取的初始阶段会是一般的商品页面，但当爬取过程进行一段时间后，亚马逊会返回另一种页面，这种页面和前一种页面不同，在一般的正常访问中不会显示。这两种页面显示的内容有所不同，因此我们在数据爬取的过程中选取了两种页面信息的交集部分，来提高数据的完整性和可信度
+ 在数据transform的过程中，有许多的数据并不是非常完整，比如没有上映时间，没有版本信息，版本分类比较随意等等。对于上映时间，如果没有，则选取最早的一条评论的时间作为上映时间，等等
+ ⭕️⭕️⭕️⭕️⭕️

### 数据血缘分析

大数据时代，数据爆发性增长，海量的、各种类型的数据在快速产生。这些庞大复杂的数据信息，通过联姻融合、转换变换、流转流通，又生成新的数据，汇聚成数据的海洋。

数据的产生、加工融合、流转流通，到最终消亡，数据之间自然会形成一种关系。我们借鉴人类社会中类似的一种关系来表达数据之间的这种关系，称之为数据的血缘关系。与人类社会中的血缘关系不同，数据的血缘关系还包含了一些特有的特征：

- **归属性**：一般来说，特定的数据归属特定的组织或者个人，数据具有归属性。
- **多源性**：同一个数据可以有多个来源（多个父亲）。一个数据可以是多个数据经过加工而生成的，而且这种加工过程可以是多个。
- **可追溯性**：数据的血缘关系，体现了数据的生命周期，体现了数据从产生到消亡的整个过程，具备可追溯性。
- **层次性**：数据的血缘关系是有层次的。对数据的分类、归纳、总结等对数据进行的描述信息又形成了新的数据，不同程度的描述信息形成了数据的层次。

#### 应用场景

+ 可以从一个演员出发，分析他演过的所有电影的信息，以及他合作过个导演和演员信息等
+ 可以从一个电影出发，寻找这个电影参演的所有演员和导演，及他们演过的其他电影

### 组员及分配比例